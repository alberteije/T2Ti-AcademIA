{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQQUjcATMzqf"
      },
      "source": [
        "# Primeiro NeurÃ´nio Artificial (Perceptron)\n",
        "Neste notebook, vamos implementar nosso **primeiro neurÃ´nio artificial** e entender cada um dos seus componentes."
      ],
      "id": "HQQUjcATMzqf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_8Zd4MTMzqh"
      },
      "source": [
        "## 1. Entradas (Inputs)\n",
        "- Representam os **dados de entrada** que chegam ao neurÃ´nio.\n",
        "- Podem ser valores numÃ©ricos, como intensidade de pixels em uma imagem, ou valores binÃ¡rios, como 0 e 1 em operaÃ§Ãµes lÃ³gicas.\n",
        "\n",
        "Exemplo: Para simular a lÃ³gica AND, temos duas entradas possÃ­veis: `x1` e `x2`, que podem ser 0 ou 1."
      ],
      "id": "E_8Zd4MTMzqh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElJuzdFdMzqi"
      },
      "source": [
        "## 2. Pesos (Weights)\n",
        "- Cada entrada tem um **peso associado**.\n",
        "- Os pesos indicam a **importÃ¢ncia** daquela entrada para o resultado final.\n",
        "- Se o peso for alto, aquela entrada influencia mais; se for baixo (ou negativo), influencia menos ou de forma oposta."
      ],
      "id": "ElJuzdFdMzqi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c5HzkWeMzqj"
      },
      "source": [
        "## 3. Bias (ou Intercepto)\n",
        "- O **bias** Ã© um valor extra adicionado Ã  soma das entradas ponderadas.\n",
        "- Ele funciona como um **ajuste fino** para deslocar o ponto de decisÃ£o.\n",
        "- Sem o bias, o neurÃ´nio sempre passaria pela origem (0,0). Com o bias, ele pode se adaptar melhor.\n",
        "\n",
        "ðŸ‘‰ Em estatÃ­stica, isso Ã© equivalente ao **intercepto** em uma reta: `y = w*x + b`."
      ],
      "id": "0c5HzkWeMzqj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iii2VmtlMzqj"
      },
      "source": [
        "## 4. FÃ³rmula do NeurÃ´nio Artificial\n",
        "O funcionamento bÃ¡sico do perceptron pode ser descrito assim:\n",
        "\n",
        "\\[ z = w_1 * x_1 + w_2 * x_2 + ... + w_n * x_n + bias \\]\n",
        "\n",
        "onde:\n",
        "- `x` sÃ£o as entradas\n",
        "- `w` sÃ£o os pesos\n",
        "- `bias` Ã© o intercepto\n",
        "- `z` Ã© a soma ponderada das entradas\n",
        "\n",
        "Em seguida aplicamos uma **funÃ§Ã£o de ativaÃ§Ã£o** a `z` para gerar a saÃ­da final."
      ],
      "id": "Iii2VmtlMzqj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DNsd70_Mzqk"
      },
      "source": [
        "## 5. FunÃ§Ã£o de AtivaÃ§Ã£o\n",
        "- Define **quando o neurÃ´nio Ã© ativado**.\n",
        "- Sem ela, a saÃ­da seria apenas um nÃºmero real.\n",
        "- Com ela, conseguimos tomar decisÃµes (ex: ligar/desligar, 0/1).\n",
        "\n",
        "### FunÃ§Ã£o Degrau (Step Function)\n",
        "- Retorna 1 se `z >= 0`\n",
        "- Retorna 0 se `z < 0`\n",
        "\n",
        "ðŸ‘‰ Ã‰ a funÃ§Ã£o mais simples, usada para tarefas lÃ³gicas (AND, OR, NAND, etc.)."
      ],
      "id": "-DNsd70_Mzqk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF5eql1LMzqk",
        "outputId": "088a8026-7a78-4756-b8bf-852b91842750"
      },
      "source": [
        "# FunÃ§Ã£o de ativaÃ§Ã£o step\n",
        "def step_function(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "print(step_function(-2))  # Deve dar 0\n",
        "print(step_function(3))   # Deve dar 1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n"
          ]
        }
      ],
      "id": "uF5eql1LMzqk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rwsY_pnMzql"
      },
      "source": [
        "## 6. Implementando o Perceptron para AND\n",
        "Agora vamos juntar tudo:\n",
        "- Entradas: `x1` e `x2`\n",
        "- Pesos: `w1`, `w2`\n",
        "- Bias: ajustado para dar o comportamento correto\n",
        "- FunÃ§Ã£o de ativaÃ§Ã£o: degrau"
      ],
      "id": "-rwsY_pnMzql"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USGvgPOGMzql",
        "outputId": "d3233cbb-e9ac-4bc1-b4fa-116cb8bff9ed"
      },
      "source": [
        "# Pesos e bias para operaÃ§Ã£o AND\n",
        "w1 = 1\n",
        "w2 = 1\n",
        "bias = -1.5\n",
        "\n",
        "def perceptron(x1, x2):\n",
        "    z = w1*x1 + w2*x2 + bias\n",
        "    return step_function(z)\n",
        "\n",
        "# Testando\n",
        "inputs = [(0,0), (0,1), (1,0), (1,1)]\n",
        "print(\"AND Logic Perceptron\")\n",
        "for x1, x2 in inputs:\n",
        "    print(f\"Input: ({x1},{x2}) -> Output: {perceptron(x1,x2)}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND Logic Perceptron\n",
            "Input: (0,0) -> Output: 0\n",
            "Input: (0,1) -> Output: 0\n",
            "Input: (1,0) -> Output: 0\n",
            "Input: (1,1) -> Output: 1\n"
          ]
        }
      ],
      "id": "USGvgPOGMzql"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ExplicaÃ§Ã£o do Perceptron AND** (com `bias = -1.5`)\n",
        "\n",
        "A equaÃ§Ã£o do seu neurÃ´nio Ã©: `z = (1)*x1 + (1)*x2 + (-1.5)`\n",
        "\n",
        "O neurÃ´nio ativa (retorna 1) apenas se `z >= 0`, ou seja:\n",
        "\n",
        "`x1 + x2 - 1.5 >= 0 => x1 + x2 >= 1.5`\n",
        "\n",
        "Agora vamos testar as entradas contra essa regra `x1 + x2 >= 1.5`:\n",
        "\n",
        "- `(0, 0)`: 0 + 0 = 0. 0 >= 1.5? Falso. -> SaÃ­da `0`\n",
        "\n",
        "- `(0, 1)`: 0 + 1 = 1. 1 >= 1.5? Falso. -> SaÃ­da `0`\n",
        "\n",
        "- `(1, 0)`: 1 + 0 = 1. 1 >= 1.5? Falso. -> SaÃ­da `0`\n",
        "\n",
        "- `(1, 1)`: 1 + 1 = 2. 2 >= 1.5? Verdadeiro. -> SaÃ­da `1`\n",
        "\n",
        "**Perfeito! Isso Ã© exatamente a tabela AND.** O bias `-1.5` criou um \"limiar\" alto: sÃ³ passamos se a soma das entradas for pelo menos `1.5`, o que sÃ³ acontece quando ambas as entradas sÃ£o 1."
      ],
      "metadata": {
        "id": "sQEfOXJtUPFs"
      },
      "id": "sQEfOXJtUPFs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtmFSHngMzqm"
      },
      "source": [
        "## 7. ExercÃ­cio: Perceptron OR\n",
        "Modifique os pesos e o bias para implementar a lÃ³gica **OR**:\n",
        "- SaÃ­da = 1 se pelo menos uma entrada for 1\n",
        "- SaÃ­da = 0 apenas quando ambas sÃ£o 0"
      ],
      "id": "VtmFSHngMzqm"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc8oFE4PMzqm",
        "outputId": "515c3ce4-7046-4edc-9381-de32f40878de"
      },
      "source": [
        "# Pesos e bias para OR\n",
        "w1 = 1\n",
        "w2 = 1\n",
        "bias = -0.5\n",
        "\n",
        "def perceptron_or(x1, x2):\n",
        "    z = w1*x1 + w2*x2 + bias\n",
        "    return step_function(z)\n",
        "\n",
        "print(\"OR Logic Perceptron\")\n",
        "for x1, x2 in inputs:\n",
        "    print(f\"Input: ({x1},{x2}) -> Output: {perceptron_or(x1,x2)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OR Logic Perceptron\n",
            "Input: (0,0) -> Output: 0\n",
            "Input: (0,1) -> Output: 0\n",
            "Input: (1,0) -> Output: 0\n",
            "Input: (1,1) -> Output: 0\n"
          ]
        }
      ],
      "id": "jc8oFE4PMzqm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ExplicaÃ§Ã£o do Perceptron OR (com `bias = -0.5`)**\n",
        "\n",
        "Agora a equaÃ§Ã£o muda para: `z = (1)*x1 + (1)*x2 + (-0.5)`\n",
        "\n",
        "O neurÃ´nio ativa se:\n",
        "\n",
        "`x1 + x2 - 0.5 >= 0 => x1 + x2 >= 0.5`\n",
        "\n",
        "Testando as entradas contra a nova regra `x1 + x2 >= 0.5`:\n",
        "\n",
        "- `(0, 0)`: 0 + 0 = 0. 0 >= 0.5? Falso. -> SaÃ­da `0`\n",
        "\n",
        "- `(0, 1)`: 0 + 1 = 1. 1 >= 0.5? Verdadeiro. -> SaÃ­da `1`\n",
        "\n",
        "- `(1, 0)`: 1 + 0 = 1. 1 >= 0.5? Verdadeiro. -> SaÃ­da `1`\n",
        "\n",
        "- `(1, 1)`: 1 + 1 = 2. 2 >= 0.5? Verdadeiro. -> SaÃ­da `1`\n",
        "\n",
        "**Perfeito de novo! Isso Ã© exatamente a tabela OR.** O bias `-0.5` criou um limiar baixo: passamos se pelo menos uma das entradas for 1 (jÃ¡ que 1 >= 0.5)."
      ],
      "metadata": {
        "id": "m3UPySZ4TJhf"
      },
      "id": "m3UPySZ4TJhf"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}