{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "id": "4fb7f376",
      "cell_type": "markdown",
      "source": "# Classificador Naive Bayes com scikit-learn\nEste notebook demonstra como usar o classificador Naive Bayes para detectar spam com uma base de e-mails simples.",
      "metadata": {}
    },
    {
      "id": "6f823b12",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# Importando bibliotecas necess√°rias\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline",
      "outputs": []
    },
    {
      "id": "2fd92c6c",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# Criando uma base de dados de e-mails com r√≥tulos 'spam' e 'ham' (n√£o-spam)\nemails = [\n    (\"Compre agora e ganhe desconto\", \"spam\"),\n    (\"Oferta exclusiva s√≥ hoje\", \"spam\"),\n    (\"Reuni√£o marcada para amanh√£\", \"ham\"),\n    (\"Seu relat√≥rio est√° pronto\", \"ham\"),\n]\n\n# Separando os textos (X) dos r√≥tulos (y)\nX = [x[0] for x in emails]  # Lista com os textos\ny = [x[1] for x in emails]  # Lista com os r√≥tulos",
      "outputs": []
    },
    {
      "id": "ae191a4c",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# Criando um pipeline para transformar os textos e treinar o modelo\nmodelo = Pipeline([\n    (\"vetorizador\", CountVectorizer()),  # Transforma os textos em vetores num√©ricos\n    (\"classificador\", MultinomialNB())   # Aplica o classificador Naive Bayes\n])\n\n# Treinando o modelo\nmodelo.fit(X, y)",
      "outputs": []
    },
    {
      "id": "f5d8d4d0",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# Testando o modelo com uma nova frase\nfrase_teste = \"falar sobre um desconto na reuni√£o de amanh√£, marquei um hor√°rio exclusivo\"\n\n# Fazendo a predi√ß√£o e mostrando as probabilidades\npredicao = modelo.predict([frase_teste])[0]\nprobs = modelo.predict_proba([frase_teste])[0]\n\n# Mostrando os resultados\nprint(f\"Frase: '{frase_teste}'\")\nprint(f\"Classifica√ß√£o prevista: {predicao}\")\nprint(f\"Probabilidades: spam = {probs[modelo.classes_.tolist().index('spam')]:.2f}, ham = {probs[modelo.classes_.tolist().index('ham')]:.2f}\")",
      "outputs": []
    },
    {
      "id": "48e2fbb9",
      "cell_type": "markdown",
      "source": "## üß† Conclus√£o\nO classificador Naive Bayes √© um modelo probabil√≠stico que usa a frequ√™ncia das palavras nos exemplos de treinamento para prever se uma nova frase √© spam ou n√£o. Mesmo com palavras neutras como 'reuni√£o', termos como 'desconto' e 'exclusivo' podem influenciar a classifica√ß√£o para spam, pois estavam associados a exemplos de spam no treinamento.",
      "metadata": {}
    }
  ]
}